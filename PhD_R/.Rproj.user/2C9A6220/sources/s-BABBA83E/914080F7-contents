########################
#COOPERATION WITH BRANA#
########################


#Initalization#
###############

library(readxl)
library(ggplot2)
library(ggthemes)
library(dplyr)
library(tidyr)
library(matrixStats)
library(caret)
library(AppliedPredictiveModeling)
library(stringr)
library(pROC)
library(readr)
library(purrr)

# Set seed for the whole session #
##################################
set.seed(333)


# Importing and initial data wrangling #
########################################


#BRANIN DATA SET#
#################
#setwd("~/GitHub/Saradnja_sa_Branom")

init_data <- read_excel("Obojene_krkrop_II150_III_IV_V150.xlsx")

# Checking the df
str(init_data)

# Let's get rid of the columns which are not needed for initial analysis
use_data <- init_data[-c(1, 3)] 

# names(init_data)
# colname_nice <- as.numeric(colnames(use_data)[2:length(use_data)])

# View(use_data)

head(names(use_data))
tail(names(use_data))

head(use_data[1:10])
tail(use_data[1:10])

head(use_data[254:257])
tail(use_data[254:257])

head(use_data[1])

# Arrange group names
use_data[[1]] <- str_replace(use_data[[1]], "DRUGA.*", "2")
use_data[[1]] <- str_replace(use_data[[1]], "TRECA.*", "3")
use_data[[1]] <- str_replace(use_data[[1]], "CETVRTA.*", "4")
use_data[[1]] <- str_replace(use_data[[1]], "PETA.*", "5")
use_data[[1]] <- str_replace(use_data[[1]], ".ETVRTA.*", "4")

# Let's properly rename the first column which holds group markings
colnames(use_data)[1] <- "Group"

# Renaming the rest of the columns that hold the relative wavelengths
# for (i in 2:ncol(use_data)) {
#   
#    colnames(use_data)[i] <- paste("wave_diff=", colnames(use_data)[i])
#    
#  }

head(colnames(use_data))

# Let's check if there are any NAs
sum(is.na(use_data) == TRUE)

# Let's make factors out of chr markings
use_data$Group <- as.factor(use_data$Group)

# Check the outcome
levels(use_data$Group)

# Make a dataset with only two groups "NC" - no cancer (or no concern, yet :P)
# and "C" - cancer. This will serve for playing arround with binary classification

data_bin <- use_data

levels(data_bin$Group)


levels(data_bin$Group) <- sub("2", "NC", levels(data_bin$Group))
levels(data_bin$Group) <- sub("3", "NC", levels(data_bin$Group))
levels(data_bin$Group) <- sub("4", "C", levels(data_bin$Group))
levels(data_bin$Group) <- sub("5", "C", levels(data_bin$Group))

levels(data_bin$Group)

head(data_bin[1:5])
tail(data_bin[1:5])

#Let's see what is the proportion of healthy (NC) vs those with some pre-cancer condition or cancer (C)
prop.table(table(data_bin$Group))



##############
#data_bin_all#
##############

# Puting in new varables that will serve as potential features for classification 

# as.matrix has to be used to transform df to matrix for matrixStats functions

data_bin_all <- data_bin %>% mutate(Mean = rowMeans(data_bin[2:length(data_bin)]),
                                   Median = rowMedians(as.matrix(data_bin[2:length(data_bin)])),
                                   Sd = rowSds(as.matrix(data_bin[2:length(data_bin)])),
                                   Max = rowMaxs(as.matrix(data_bin[2:length(data_bin)])),
                                   Min = rowMins(as.matrix(data_bin[2:length(data_bin)])))

data_bin_all <- tbl_df(data_bin_all)

head(colnames(data_bin_all))
tail(colnames(data_bin_all))

head(data_bin_all[1:5])
head(data_bin_all[(length(data_bin_all)-5):length(data_bin_all)])

################
#data_bin_small#
################

data_bin_small <- data_bin_all[, c(1, (length(names(data_bin_all))-4):length(names(data_bin_all)))]
names(data_bin_small)

head(data_bin_small)
tail(data_bin_small)

# Preprocessing & Training #
############################

# Create initial custom trainControl: myControl
myControl <- trainControl(
  method = "cv", number = 10,
  summaryFunction = twoClassSummary,
  classProbs = TRUE, # IMPORTANT!
  verboseIter = F
)

# Probing with "glmnet"#
########################

#Using data_bin#
################

# Print model to console
model_glmnet1

# Print maximum ROC statistic
max(model_glmnet1[["results"]]$ROC) # max ROC = 0.7556316

# Model summary
summary(model_glmnet1)

# Plot the model
plot(model_glmnet1)

# find out variable importance
varImp(model_glmnet1)
plot(varImp(model_glmnet1))

# Probing with "glmnet" and pca

# Fit glmnet model: model; preprocessing with standardization, nzv and pca
model_glmnet2 <- train(
  Group ~., data = data_bin,
  method = "glmnet",
  trControl = myControl,
  preProcess = c("zv", "center", "scale", "pca")
)

# Print model to console
model_glmnet2

# Print maximum ROC statistic
max(model_glmnet2[["results"]]$ROC) # max ROC = 0.754

# Plot the model
plot(model_glmnet2)

# Probing with "gbm"

# Fit "gbm" model; preprocessing with standardization and removing nzv
model_gbm1 <- train(
  Group ~., data = data_bin,
  method = "gbm",
  trControl = myControl,
  preProcess = c("nzv", "center", "scale")
)

# Print model to console
model_gbm1

# Print maximum ROC statistic
max(model_gbm1[["results"]]$ROC) # max ROC = 0.7556316

# Model summary: 20 most important predictors
summary(model_gbm1, cBars = 20, las = 1)[1:20,]

# Plot the model behaviour in regard to change of alpha and lambda
plot(model_gbm1)

# Just probing with gbm and pca

# Fit "gbm" model; preprocessing with standardization, zv and pca
model_gbm2 <- train(
  Group ~., data = data_bin,
  method = "gbm",
  trControl = myControl,
  preProcess = c("zv", "center", "scale", "pca")
)

# Print model to console
model_gbm2

# Print maximum ROC statistic
max(model_gbm2[["results"]]$ROC) # max ROC = 0.754

# Model summary: 20 most important predictors
summary(model_gbm2, cBars = 20, las = 1)[1:20,]

# Plot the model behaviour in regard to change of alpha and lambda
plot(model_gbm2)

# Let's try "random forest" #

# With nzv removal and standardization of predictors
model_rf1 <- train(
  Group ~., data = data_bin,
  method = "ranger",
  trControl = myControl,
  preProcess = c("nzv", "center", "scale")
)


model_rf1
max(model_rf1[["results"]]$ROC) #0.7635

# With zv removal, standardization and pca
model_rf2 <- train(
  Group ~., data = data_bin,
  method = "ranger",
  trControl = myControl,
  preProcess = c("zv", "center", "scale", "pca")
)

model_rf2
max(model_rf2[["results"]]$ROC) #0.776


#Podaci - Igor#
###############

init_data<-read_excel("Podaci_Igor/IGOR HUT TTRPSouthend2015.xlsx")

head(names(init_data))

use_data<-init_data[-(1:3)] # First three columns are not needed for analysis

# Let's make factors out of chr markings
use_data$Case<-as.factor(use_data$Case)

# Check the outcome
levels(use_data$Case)

# Putting all the CANCER* factor levels iside one CANCER wraper 
levels(use_data$Case)<-sub("CANCER.*", "CANCER", levels(use_data$Case))

# Check the situation
levels(use_data$Case)

summary(use_data$Case)


# Let's properly rename the first column which holds group markings
colnames(use_data)[1] <- "Group"

# Make a dataset with only two groups "NC" - no cancer (or no concern, yet :P)
# and "C" - cancer. This will serve for playing arround with binary classification
data_bin <- use_data

levels(data_bin$Group)

levels(data_bin$Group) <- sub("Negative", "NC", levels(data_bin$Group))
levels(data_bin$Group) <- sub("BL", "NC", levels(data_bin$Group))
levels(data_bin$Group) <- sub("LG", "NC", levels(data_bin$Group))
levels(data_bin$Group) <- sub("MD", "NC", levels(data_bin$Group))
levels(data_bin$Group) <- sub("SD", "C", levels(data_bin$Group))
levels(data_bin$Group) <- sub("CIN2&HG", "C", levels(data_bin$Group))
levels(data_bin$Group) <- sub("CANCER", "C", levels(data_bin$Group))

levels(data_bin$Group)

head(data_bin[1:10])
tail(data_bin[1:10])

#Let's see what is the proportion of healthy (NC) vs those with some pre-cancer condition or cancer (C)
prop.table(table(data_bin$Group))

# Preprocessing & Training #
############################


# Create initial custom trainControl: myControl
myControl <- trainControl(
  method = "cv", number = 10,
  summaryFunction = twoClassSummary,
  classProbs = TRUE, # IMPORTANT!
  verboseIter = F
)

# Probing with "glmnet"#
########################


#Using data_bin#
################

# Fit glmnet model: model; preprocessing with standardization and removing nzv
model_glmnet1 <- train(
  Group ~., data = data_bin,
  method = "glmnet",
  trControl = myControl,
  preProcess = c("nzv", "center", "scale")
)

# Print model to console
model_glmnet1

# Print maximum ROC statistic
max(model_glmnet1[["results"]]$ROC) # max ROC = 0.7402381

# Model summary
summary(model_glmnet1)

# Plot the model
plot(model_glmnet1)

# find out variable importance
varImp(model_glmnet1)
plot(varImp(model_glmnet1))



# Probing with "glmnet" and pca
# Fit glmnet model: model; preprocessing with standardization, nzv and pca
model_glmnet2 <- train(
  Group ~., data = data_bin,
  method = "glmnet",
  trControl = myControl,
  preProcess = c("zv", "center", "scale", "pca")
)

# Print model to console
model_glmnet2

# Print maximum ROC statistic
max(model_glmnet2[["results"]]$ROC) # max ROC = 0.734

# Plot the model
plot(model_glmnet2)

# Probing with "gbm"

# Fit "gbm" model; preprocessing with standardization and removing nzv
model_gbm1 <- train(
  Group ~., data = data_bin,
  method = "gbm",
  trControl = myControl,
  preProcess = c("nzv", "center", "scale")
)

# Print model to console
model_gbm1

# Print maximum ROC statistic
max(model_gbm1[["results"]]$ROC) # max ROC = 0.75325

# Model summary: 20 most important predictors
summary(model_gbm1, cBars = 20, las = 1)[1:20,]

# Plot the model behaviour in regard to change of alpha and lambda
plot(model_gbm1)

# Just probing with gbm and pca

# Fit "gbm" model; preprocessing with standardization, zv and pca
model_gbm2 <- train(
  Group ~., data = data_bin,
  method = "gbm",
  trControl = myControl,
  preProcess = c("zv", "center", "scale", "pca")
)

# Print model to console
model_gbm2

# Print maximum ROC statistic
max(model_gbm2[["results"]]$ROC) # max ROC = 0.7615

# Model summary: 20 most important predictors
summary(model_gbm2, cBars = 20, las = 1)[1:20,]

# Plot the model behaviour in regard to change of alpha and lambda
plot(model_gbm2)

# Let's try "random forest"#

# With nzv (near zero variance predictors removal) and standardistion of predictors
model_rf1 <- train(
  Group ~., data = data_bin,
  method = "ranger",
  trControl = myControl,
  preProcess = c("nzv", "center", "scale")
)


model_rf1
max(model_rf1[["results"]]$ROC) #0.7183333  0.85  0.5119048


# With zv removal, standardisation and pca

model_rf2 <- train(
  Group ~., data_bin,
  method = "ranger",
  trControl = myControl,
  preProcess = c("zv", "center", "scale", "pca")
)


model_rf2
max(model_rf2[["results"]]$ROC) #0.6245238  0.7300000  0.3738095
